{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- 4 binary classifiers (I/E, T/F, N/S, P/J axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification #, TrainingArguments, Trainer\n",
    "from transformers import AlbertTokenizer #, AlbertModel\n",
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/deimann/mbti-project/IE_train_balanced_2lab/checkpoint-6670\", num_labels=2)\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer,max_length=512, truncation=True, device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_feather(\"/media/data/mbti-reddit/disprop_sample100k_total.feather\") \n",
    "df=pd.concat([df,df.sample(30000, random_state=1)]).drop_duplicates(keep=False) #drops the subset that has been used for training/testing\n",
    "df=df.drop(columns=['authors','subreddit'])\n",
    "\n",
    "#final test set\n",
    "df=df.sample(10000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced dataset\n",
    "\n",
    "df = pd.read_feather('/media/data/mbti-reddit/disprop_sample100k_total.feather')\n",
    "df=df.sample(20000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess DF\n",
    "df['labels'] = df['labels'].replace(['INTP','ISTP','INFP','ISFP','INTJ','ISTJ','INFJ','ISFJ',\n",
    "                                     'ENTP','ESTP','ENFP','ESFP','ENTJ','ESTJ','ENFJ','ESFJ'], \\\n",
    "                                    ['I','I','I','I','I','I','I','I','E','E','E','E','E','E','E','E']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deimann/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "true_labels = df['labels'].to_list()\n",
    "predicted_labels = []\n",
    "\n",
    "text = df['comments'].to_list()\n",
    "\n",
    "for test in text:\n",
    "  predicted_label = pipeline(test, batch_size=16)[0]['label']\n",
    "  if predicted_label == 'LABEL_0':\n",
    "    predicted_labels.append('I')\n",
    "  elif predicted_label == 'LABEL_1':\n",
    "    predicted_labels.append('E')\n",
    "  else:\n",
    "    print(\"unexpected label\")\n",
    "    print(predicted_label)\n",
    "  \n",
    "  #to show the predicted labels see below\n",
    "  #print(test[\"text\"])\n",
    "  #print(test[\"label\"])\n",
    "  #print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'True':true_labels, 'Predicted':predicted_labels}\n",
    "truefalse=pd.DataFrame(d)\n",
    "truefalse.to_csv('/home/deimann/mbti-eval/2/IE_classification_bal_2clas_cp8000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/IE_train_2lab/checkpoint-8000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.00      0.00      0.00      3095\n",
      "           I       0.69      1.00      0.82      6905\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.35      0.50      0.41     10000\n",
      "weighted avg       0.48      0.69      0.56     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/IE_train_2lab/checkpoint-8000\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/IE_train_2lab/checkpoint-14000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.39      0.17      0.24      3095\n",
      "           I       0.70      0.88      0.78      6905\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.55      0.53      0.51     10000\n",
      "weighted avg       0.61      0.66      0.61     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/IE_train_2lab/checkpoint-14000\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/IE_train_balanced_2lab/checkpoint-6670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.52      0.72      0.60      4945\n",
      "           I       0.56      0.36      0.44      5055\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.54      0.54      0.52     10000\n",
      "weighted avg       0.54      0.54      0.52     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/IE_train_balanced_2lab/checkpoint-6670\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S/N classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/deimann/mbti-project/SN_train/checkpoint-40733\", num_labels=16)\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer,max_length=512, truncation=True, device=1)\n",
    "\n",
    "df = pd.read_feather(\"//media/data/mbti-reddit/preprocessed_df_new.feather\") \n",
    "df=df.drop(columns=['authors','subreddit'])\n",
    "df=pd.concat([df,df.sample(80000, random_state=1)]).drop_duplicates(keep=False) #drops the subset that has been used for training/testing\n",
    "\n",
    "#final test set\n",
    "df=df.sample(10000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess DF\n",
    "df['labels'] = df['labels'].replace(['ISTP','ESTP','ISFP','ESFP','ISTJ','ESTJ','ISFJ','ESFJ',\n",
    "                                     'INTP','ENTP','ENFP','INFP','ENTJ','INTJ','ENFJ','INFJ'], \\\n",
    "                                    ['S','S','S','S','S','S','S','S','N','N','N','N','N','N','N','N']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deimann/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = df['labels'].to_list()\n",
    "predicted_labels = []\n",
    "\n",
    "text = df['comments'].to_list()\n",
    "\n",
    "\n",
    "for test in text[:10000]:\n",
    "  predicted_label = pipeline(test)[0]['label']\n",
    "  if predicted_label == 'LABEL_0':\n",
    "    predicted_labels.append('S')\n",
    "  elif predicted_label == 'LABEL_1':\n",
    "    predicted_labels.append('N')\n",
    "\n",
    "  else:\n",
    "    print(\"unexpected label\")\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_labels = df['labels'].to_list()\n",
    "d = {'True':true_labels, 'Predicted':predicted_labels}\n",
    "truefalseinitial_old=pd.DataFrame(d)\n",
    "truefalseinitial_old.to_csv('/home/deimann/mbti-eval/2/SN_classification_cp40733.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/SN_train/checkpoint-29095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.75      1.00      0.85      7465\n",
      "           S       0.00      0.00      0.00      2535\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.37      0.50      0.43     10000\n",
      "weighted avg       0.56      0.75      0.64     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/SN_train/checkpoint-29095\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/SN_train/checkpoint-40733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.75      0.91      0.82      7465\n",
      "           S       0.32      0.12      0.18      2535\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.54      0.52      0.50     10000\n",
      "weighted avg       0.64      0.71      0.66     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/SN_train/checkpoint-40733\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T/F classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/deimann/mbti-project/TF_train_bal_MBTIonly/checkpoint-2668\", num_labels=2)\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer,max_length=512, truncation=True, device=1)\n",
    "\n",
    "df = pd.read_feather(\"//media/data/mbti-reddit/preprocessed_df_new.feather\") \n",
    "df=df.drop(columns=['authors','subreddit'])\n",
    "df=pd.concat([df,df.sample(80000, random_state=1)]).drop_duplicates(keep=False) #drops the subset that has been used for training/testing\n",
    "\n",
    "#final test set\n",
    "df=df.sample(10000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MBTI subset and non-MBTI subset elimination for testing TF_train_bal_MBTIonly against TF_train_bal_noMBTI\n",
    "\n",
    "df = pd.read_feather(\"/media/data/mbti-reddit/prop_sample_0025_total.feather\") \n",
    "subsets = pd.concat([pd.read_feather('/media/data/mbti-reddit/disprop_sample100k_no_mbti.feather').sample(30000, random_state=1),pd.read_feather('/media/data/mbti-reddit/disprop_sample50k_mbtionly.feather').sample(30000, random_state=1)])\n",
    "df=pd.concat([df,subsets]).drop_duplicates(keep=False) #drops the subset that has been used for training/testing\n",
    "df=df.drop(columns=['authors','subreddit'])\n",
    "\n",
    "df=df.sample(10000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess DF\n",
    "df['labels'] = df['labels'].replace(['ISTP','ESTP','ISTJ','ESTJ','INTP','ENTP','ENTJ','INTJ',\n",
    "                                     'ISFP','ESFP','ENFP','INFP','ISFJ','ESFJ','ENFJ','INFJ'], \\\n",
    "                                    ['T','T','T','T','T','T','T','T','F','F','F','F','F','F','F','F']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deimann/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = df['labels'].to_list()\n",
    "predicted_labels = []\n",
    "\n",
    "text = df['comments'].to_list()\n",
    "\n",
    "\n",
    "for test in text:\n",
    "  predicted_label = pipeline(test)[0]['label']\n",
    "  if predicted_label == 'LABEL_0':\n",
    "    predicted_labels.append('T')\n",
    "  elif predicted_label == 'LABEL_1':\n",
    "    predicted_labels.append('F')\n",
    "\n",
    "  else:\n",
    "    print(\"unexpected label\")\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df['labels'].to_list()\n",
    "d = {'True':true_labels, 'Predicted':predicted_labels}\n",
    "truefalse=pd.DataFrame(d)\n",
    "truefalse.to_csv('/home/deimann/mbti-eval/2/TF_bal-classification_noMBTI_cp6546.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/SN_train/checkpoint-40733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.46      0.44      0.45      4072\n",
      "           T       0.62      0.64      0.63      5928\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.54      0.54      0.54     10000\n",
      "weighted avg       0.56      0.56      0.56     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/TF_train/checkpoint-40733\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/TF_train_bal_noMBTI/checkpoint-6546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.52      0.52      0.52      4387\n",
      "           T       0.62      0.62      0.62      5613\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.57      0.57      0.57     10000\n",
      "weighted avg       0.58      0.58      0.58     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/TF_train_bal_noMBTI/checkpoint-6546\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/TF_train_bal_MBTIonly/checkpoint-2668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.54      0.51      0.52      4387\n",
      "           T       0.63      0.66      0.65      5613\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.59      0.59      0.59     10000\n",
      "weighted avg       0.59      0.60      0.59     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/TF_train_bal_MBTIonly/checkpoint-2668\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P/J classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/deimann/mbti-project/PJ_train_MBTIonly/checkpoint-49784\", num_labels=16)\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer,max_length=512, truncation=True, device=1)\n",
    "\n",
    "df = pd.read_feather(\"//media/data/mbti-reddit/preprocessed_df_new.feather\") \n",
    "df=df.drop(columns=['authors','subreddit'])\n",
    "df=pd.concat([df,df.sample(80000, random_state=1)]).drop_duplicates(keep=False) #drops the subset that has been used for training/testing\n",
    "\n",
    "#final test set\n",
    "df=df.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess DF\n",
    "df['labels'] = df['labels'].replace(['ISTP','ESTP','INTP','ENTP','ISFP','ESFP','ENFP','INFP',\n",
    "                                     'ISTJ','ESTJ','ENTJ','INTJ','ISFJ','ESFJ','ENFJ','INFJ'], \\\n",
    "                                    ['P','P','P','P','P','P','P','P','J','J','J','J','J','J','J','J']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deimann/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = df['labels'].to_list()\n",
    "predicted_labels = []\n",
    "\n",
    "text = df['comments'].to_list()\n",
    "\n",
    "\n",
    "for test in text:\n",
    "  predicted_label = pipeline(test)[0]['label']\n",
    "  if predicted_label == 'LABEL_0':\n",
    "    predicted_labels.append('P')\n",
    "  elif predicted_label == 'LABEL_1':\n",
    "    predicted_labels.append('J')\n",
    "\n",
    "  else:\n",
    "    print(\"unexpected label\")\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df['labels'].to_list()\n",
    "d = {'True':true_labels, 'Predicted':predicted_labels}\n",
    "truefalse=pd.DataFrame(d)\n",
    "truefalse.to_csv('/home/deimann/mbti-eval/2/PJ_classification_MBTIonly_cp49784.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deimann/mbti-project/PJ_train/checkpoint-49784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           J       0.47      0.15      0.23      3910\n",
      "           P       0.62      0.89      0.73      6090\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.55      0.52      0.48     10000\n",
      "weighted avg       0.56      0.60      0.54     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/deimann/mbti-project/PJ_train/checkpoint-49784\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"//home/deimann/mbti-eval/2/PJ_classification_MBTIonly_cp49784.csv\")\n",
    "print(classification_report(true_labels,predicted_labels, zero_division=0.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
